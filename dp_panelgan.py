# -*- coding: utf-8 -*-
"""DP-PanelGAN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1psGmbvzDKjlQxjo8O9096eK6PCiQNqBy
"""

from __future__ import print_function, division
from keras.datasets import mnist
from tensorflow.keras.optimizers import RMSprop
from functools import partial
import tensorflow as tf
import argparse
import random
import seaborn as sns
import os
import numpy as np
import keras
from tensorflow.keras import backend as K
from functools import partial
from google.colab import drive
from google.colab import files
from __future__ import print_function, division
import os
from sklearn.linear_model import LinearRegression
import sys
import numpy as np
import matplotlib.pyplot as plt
from keras.layers import Input, Dense, Reshape, Flatten, Dropout
from keras.layers import BatchNormalization, Activation, ZeroPadding2D
from keras.layers import Input, Dense, Reshape, Flatten, Dropout, LSTM, GRU, Bidirectional, TimeDistributed, MultiHeadAttention, Attention, Layer, Softmax
from keras.layers import LeakyReLU
from keras.layers.convolutional import UpSampling2D, Conv2D, Conv1D, Conv2DTranspose
from keras.models import Sequential, Model
from tensorflow.keras.optimizers import Adam
import tensorflow as tf
import pandas as pd
import io
import time
from scipy.stats import pearsonr
from keras.datasets import mnist
from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, GaussianNoise
from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D
from keras.layers import MaxPooling2D, LeakyReLU
from keras.layers.convolutional import UpSampling2D, Conv2D
from keras.models import Sequential, Model
from keras import losses
import keras.backend as K

# for reproducability
seed=1
os.environ['PYTHONHASHSEED'] = str(seed)
# For working on GPUs from "TensorFlow Determinism"
os.environ["TF_DETERMINISTIC_OPS"] = str(seed)
np.random.seed(seed)
random.seed(seed)
tf.random.set_seed(seed)

#drive.mount('/content/drive')

#read data
data = pd.read_csv('prescriptions_new.csv', sep = ',', na_values=['(NA)']).fillna(0)
data = data.iloc[:,[2,3,5]]

print(pd.DataFrame(data).describe().loc[['min','mean', 'max', 'std']])

# obtain correlations
corr_data = pd.DataFrame(data).corr()
corr_data = np.array(corr_data)
corr_data = np.array(corr_data).reshape(len(corr_data)*len(corr_data))

# obtain regression
real_fit = LinearRegression(fit_intercept = True).fit(data.iloc[:,1:4], data.iloc[:,0])
print(real_fit.intercept_)
print("coefs")
print(real_fit.coef_)

# scale data
from sklearn.preprocessing import MinMaxScaler
scaler0 = MinMaxScaler(feature_range= (-1, 1))
scaler0 = scaler0.fit(data)
data = scaler0.transform(data)
data = np.array(data).reshape(1407,52,3)

# inverse scale data
gen_imgs1 = np.array(data).reshape(1407*52,3)
#gen_imgs1 = pd.DataFrame(gen_imgs1).transpose()
gen_imgs1 = scaler0.inverse_transform(gen_imgs1)

# reshape data and describe summary statistics
gen = np.array(gen_imgs1).reshape(1407,52,3)
plt.imshow(tf.reduce_mean(gen[:,:,:], axis = 0))
print(pd.DataFrame(tf.reduce_mean(gen[:,:,:], axis = 0)).describe())
gen_imgs1 = np.array(gen_imgs1)

# model to get utility on real data
GAN_fit = LinearRegression().fit(gen_imgs1[:,1:3], gen_imgs1[:,0])
MAPD = np.mean(abs((real_fit.coef_-GAN_fit.coef_)/real_fit.coef_))*100
MSE = np.mean((real_fit.coef_-GAN_fit.coef_)**2)
MAE = np.mean(abs(real_fit.coef_-GAN_fit.coef_))
print("MAPD")
print(MAPD)

# get correlations
corr_artificial = pd.DataFrame(gen_imgs1)
corr_artificial = corr_artificial.corr()
corr_artificial = np.array(corr_artificial)
corr_artificial = np.array(corr_artificial).reshape(len(corr_artificial)*len(corr_artificial))
corr = pearsonr(corr_artificial,corr_data)[0]
print("correlation")
print(corr)

# get time series correlations
print("time correlation prescriptions")
print(pearsonr(tf.reduce_mean(gen[:,:,:], axis = 0)[2:52,0],tf.reduce_mean(gen[:,:,:], axis = 0)[1:51,0])[0])
print("time correlation calls")
print(pearsonr(tf.reduce_mean(gen[:,:,:], axis = 0)[2:52,2],tf.reduce_mean(gen[:,:,:], axis = 0)[1:51,2])[0])

# self attention with 2D convolution

class SelfAttention2D(Layer):

    def __init__(self, reduced_filters, **kwargs):
        self.reduced_filters = reduced_filters
        super(SelfAttention2D, self).__init__(**kwargs)

    def build(self, input_shape):

        self.w_f = self.add_weight(name='w_f',
                                   shape=(1, 1, input_shape[-1], self.reduced_filters),
                                   initializer='glorot_uniform',
                                   trainable=True)

        self.w_g = self.add_weight(name='w_g',
                                   shape=(1, 1, input_shape[-1], self.reduced_filters),
                                   initializer='glorot_uniform',
                                   trainable=True)

        self.w_h = self.add_weight(name='w_h',
                                   shape=(1, 1, input_shape[-1], self.reduced_filters),
                                   initializer='glorot_uniform',
                                   trainable=True)

        self.w_v = self.add_weight(name='w_v',
                                   shape=(1, 1, self.reduced_filters, input_shape[-1]),
                                   initializer='glorot_uniform',
                                   trainable=True)

        self.gamma = self.add_weight(name='gamma',
                                     shape=(1, ),
                                     initializer='zero',
                                     trainable=True)

        super(SelfAttention2D, self).build(input_shape)

    def call(self, x):

        x_shape = tf.shape(x)
        x_f = tf.keras.backend.conv2d(x,self.w_f,padding="same")
        x_g = tf.keras.backend.conv2d(x,self.w_g,padding="same")
        x_h = tf.keras.backend.conv2d(x,self.w_h,padding="same")

        x_f = tf.reshape(x_f, (x_shape[0], x_shape[1] * x_shape[2], -1))
        x_g = tf.reshape(x_g, (x_shape[0], x_shape[1] * x_shape[2], -1))
        x_h = tf.reshape(x_h, (x_shape[0], x_shape[1] * x_shape[2], -1))

        y = tf.matmul(x_f, x_g, transpose_b=True) # attention map
        y = tf.nn.softmax(y, axis = 1)
        y = tf.matmul(y, x_h)
        y = tf.reshape(y, (x_shape[0], x_shape[1], x_shape[2], -1))
        y = tf.keras.backend.conv2d(y,self.w_v,padding="same")
        y = self.gamma * y + x
        return y

# convolution with spectral normalization (see Zhang et al. 2019 paper)

class ConvSN2D(Conv2D):
    def __init__(
            self,
            filters,
            kernel_size,
            strides=(1, 1),
            padding='valid',
            data_format=None,
            dilation_rate=(1, 1),
            activation=None,
            use_bias=True,
            kernel_initializer='glorot_uniform',
            bias_initializer='zeros',
            kernel_regularizer=None,
            bias_regularizer=None,
            activity_regularizer=None,
            kernel_constraint=None,
            bias_constraint=None,
            power_iterations = 1,
            **kwargs):

        super(ConvSN2D, self).__init__(
            filters=filters,
            kernel_size=kernel_size,
            strides=strides,
            padding=padding,
            data_format=data_format,
            dilation_rate=dilation_rate,
            activation=activation,
            use_bias=use_bias,
            kernel_initializer=kernel_initializer,
            bias_initializer=bias_initializer,
            kernel_regularizer=kernel_regularizer,
            bias_regularizer=bias_regularizer,
            activity_regularizer=activity_regularizer,
            kernel_constraint=self.spectrally_norm,
            bias_constraint=bias_constraint,
            **kwargs)

        assert power_iterations>=1, "The number of power iterations should be positive integer"

        self.Ip = power_iterations
        self.u = self.add_weight(
            name='W_u',
            shape=(1, filters),
            initializer='random_uniform',
            trainable=False
        )

    def spectrally_norm(self, w):
        W_mat = tf.transpose(w, (3, 2, 0, 1))  # (h, w, i, o) => (o, i, h, w)
        W_mat = tf.reshape(W_mat, [tf.shape(W_mat)[0], -1])  # (o, i * h * w)

        _u = self.u
        _v = None

        for _ in range(self.Ip):
            _v = self.l2_norm(tf.matmul(_u, W_mat))
            _u = self.l2_norm(tf.matmul(_v, W_mat, transpose_b=True))

        sigma = tf.reduce_sum(tf.matmul(_u, W_mat) * _v)
        sigma = tf.cond(sigma == 0, lambda: 1e-8, lambda: sigma)

        self.u.assign(tf.keras.backend.in_train_phase(_u, self.u))
        return w / sigma

    def l2_norm(self, x):
        return x / tf.sqrt(tf.reduce_sum(tf.square(x)) + 1e-8)

## define GAN with self attention

class SAGAN():
    def __init__(self, privacy = False):
      self.img_rows = 52 # 52 weeks
      self.img_cols = 3 # 3 variables
      self.channels = 1 # 1 channels with customer data
      self.img_shape = (self.img_rows, self.img_cols) # shape of X_i from paper
      self.latent_dim = 3 # latent dim is equal to variables

      optimizer = keras.optimizers.Adam()
      self.discriminator = self.build_discriminator()
      self.discriminator.compile(loss='binary_crossentropy', # hinge or binary_crossentropy
                                 optimizer=optimizer,
                                 metrics=['accuracy'])

      # Build the generator
      self.generator = self.build_generator()
      self.generator.summary()

      # The generator takes noise as input and generates imgs
      z = Input(shape=(self.latent_dim,))
      img = self.generator(z)

      # For the combined model we will only train the generator
      self.discriminator.trainable = False

      # The discriminator takes generated images as input and determines validity
      valid = self.discriminator(img)

      # The combined model  (stacked generator and discriminator)
      # Trains the generator to fool the discriminator
      self.combined = Model(z, valid)
      self.combined.compile(loss='binary_crossentropy', optimizer=optimizer) # Hinge or binary_cross_entropy


    def build_generator(self):
      noise = Input(shape=(self.latent_dim,))
      y = Dense(self.img_rows*self.img_cols, input_dim=self.latent_dim)(noise)
      #y = LeakyReLU()(y)
      y = Reshape((self.img_rows,self.img_cols,self.channels))(y)
      y = ConvSN2D(4, kernel_size= 2, strides=1, padding="same")(y)
      #y = BatchNormalization()(y)
      #y = LeakyReLU()(y)
      y = SelfAttention2D(4)(y) # self attention layer
      img = Conv2D(1, kernel_size = 2, padding="same", activation="tanh")(y)
      return Model(noise, img)

    def build_discriminator(self):

        model = Sequential()
        model.add(Flatten(input_shape = self.img_shape))
        model.add(Dense(4))
        #model.add(BatchNormalization())
        model.add(Dense(1, activation='sigmoid'))

        img = Input(shape=self.img_shape)
        validity = model(img)
        model.summary()

        return Model(img, validity)

    def train(self, iterations, batch_size, sample_interval, early_stopping, early_stopping_value, generator_losses = [], discriminator_acc = [], correlations = [], accuracy = [], MAPD_collect = [],MSE_collect = [], MAE_collect = []):
      # Adversarial ground truths
      valid = np.ones((batch_size, 1))
      fake = np.zeros((batch_size, 1))
      corr = 0
      MAPD = 0
      MSE = 0
      MAE = 0

      for epoch in range(iterations):

            # ---------------------
            #  Train Discriminator
            # ---------------------
            # Select a random batch of images
            idx = np.random.randint(0, data.shape[0], batch_size)
            imgs = data[idx]

            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))

            # Generate a batch of new images
            gen_imgs = self.generator.predict(noise, verbose = False)
            gen_imgs = gen_imgs.reshape(batch_size, self.img_rows, self.img_cols)

            # Train the discriminator
            d_loss_real = self.discriminator.train_on_batch(imgs, valid)
            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)
            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

            # ---------------------
            #  Train Generator
            # ---------------------
            # Train the generator (to have the discriminator label samples as valid)

            noise = np.random.normal(0, 1,  (batch_size, self.latent_dim))
            g_loss = self.combined.train_on_batch(noise, valid)
            generator_losses = np.append(generator_losses, g_loss)

            if epoch % sample_interval == 0:
              # Plot the progress and save model
              print ("%d [D loss: %f, acc.: %.2f%%] [G loss: %f, corr: %f, MAPD: %f, MSE: %f, MAE: %f]" % (epoch, d_loss[0], 100*d_loss[1], g_loss, corr, MAPD, MSE, MAE))

              # Gets correlation, MSE, MAPD, MAE, and others.
              sample_size = len(data)
              noise = np.random.normal(0, 1,  (sample_size, self.latent_dim))
              gen_imgs1 = self.generator.predict(noise, verbose = False)
              gen_imgs1 = np.array(gen_imgs1).reshape(sample_size*52,3)
              gen_imgs1 = scaler0.inverse_transform(gen_imgs1)

              print(pd.DataFrame(gen_imgs1).describe().loc[['min','mean', 'max', 'std']])
              gen = np.array(gen_imgs1).reshape(sample_size,52,3)
              plt.imshow(tf.reduce_mean(gen[:,:,:], axis = 0))
              plt.show()

              # model
              GAN_fit = LinearRegression().fit(gen_imgs1[:,1:3], gen_imgs1[:,0])
              MAPD = np.mean(abs((real_fit.coef_-GAN_fit.coef_)/real_fit.coef_))*100
              MSE = np.mean((real_fit.coef_-GAN_fit.coef_)**2)
              MAE = np.mean(abs(real_fit.coef_-GAN_fit.coef_))

              corr_artificial = pd.DataFrame(gen_imgs1)
              corr_artificial = corr_artificial.corr()
              corr_artificial = np.array(corr_artificial)
              corr_artificial = np.array(corr_artificial).reshape(len(corr_artificial)*len(corr_artificial))
              corr = pearsonr(corr_artificial,corr_data)[0]

      self.generator.save("prescriptions_i1000.h5") # save model


if __name__ == '__main__':
  random.seed(1)
  np.random.seed(1)
  tf.random.set_seed(1)

  iterations = 1000
  N = len(data)
  batch_size = 100
  epochs = iterations/(N/batch_size)
  print(epochs)

  # initialize model
  sagan = SAGAN(privacy = False)

  # train model
  sagan.train(iterations=(iterations), batch_size=batch_size, sample_interval=100, early_stopping = False, early_stopping_value = None)

# generate samples for evaluation

random.seed(1)
np.random.seed(1)
tf.random.set_seed(1)

# load model with custom keras layers
generator = keras.models.load_model('prescriptions_without_privacy_i1000.h5', custom_objects={"SelfAttention2D": SelfAttention2D, "ConvSN2D": ConvSN2D})

# sample data
sample_size = len(data) # sample is same size as real data
noise = np.random.normal(0, 1, (sample_size, 3)) # sample normal noise
gen_imgs1 = generator.predict(noise, verbose = False) # predict generator over noise to obtain sample
gen_imgs1 = np.array(gen_imgs1).reshape(sample_size*52,3) # reshape data to physicians matrix
gen_imgs1 = scaler0.inverse_transform(gen_imgs1) # scale data to original scaling
print(pd.DataFrame(gen_imgs1).describe().loc[['min','mean', 'max', 'std']]) # print summary stats
gen = np.array(gen_imgs1).reshape(sample_size,52,3) # scale data to physicians matrix
plt.imshow(tf.reduce_mean(gen[:,:,:], axis = 0)) # plot matrix summarized over all customers, time and vars.
plt.show()
np.savetxt("prescriptions_without_privacy_i1000.csv", gen_imgs1, delimiter=",") # save data

# calculate utility
GAN_fit = LinearRegression().fit(gen_imgs1[:,1:3], gen_imgs1[:,0])
MAPD = np.mean(abs((real_fit.coef_-GAN_fit.coef_)/real_fit.coef_))*100
MSE = np.mean((real_fit.coef_-GAN_fit.coef_)**2)
MAE = np.mean(abs(real_fit.coef_-GAN_fit.coef_))

# calculate correlations
corr_artificial = pd.DataFrame(gen_imgs1)
corr_artificial = corr_artificial.corr()
corr_artificial = np.array(corr_artificial)
corr_artificial = np.array(corr_artificial).reshape(len(corr_artificial)*len(corr_artificial))
corr = pearsonr(corr_artificial,corr_data)[0]

# results
print(corr)
print(MAPD)
print(MSE)
print(MAE)

"""# with differential privacy"""

!pip install tensorflow_privacy --quiet # install tensorflow differential privacy

from absl import app
from absl import flags
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy
from tensorflow_privacy.privacy.optimizers.dp_optimizer_keras import DPKerasSGDOptimizer, DPKerasAdamOptimizer
from tensorflow_privacy.privacy.analysis.compute_dp_sgd_privacy_lib import compute_dp_sgd_privacy

# hyperparams
N = len(data)
print(N)
batch_size = 100
iterations = 1000
num_microbatches = 100

epochs = iterations/(N/batch_size)
print("the number of epochs is " + str(epochs))
lr = 0.001
noise_multiplier = 0
l2_norm_clip = 2
delta= 1/N
compute_dp_sgd_privacy(N, batch_size, noise_multiplier,
                         epochs, delta)

#parameters are clipping = 2, batch size = 100, lot size = 100
#- iterations 100 = noise multiplier 0.6029
#- iterations 500 = noise multiplier 0.8616
#- iterations 1000 = noise multiplier  1.0574
#- iterations 2000 = noise multiplier 1.348
#- iterations 5000 = noise multiplier 1.965
#- iterations 10000 = noise multiplier 2.69

# epsilon = 13, noise multiplier = 1.0574
# epsilon = 3, 2.767
# epsilon = 1, 6.81
# epsilon = 0.5, 12.34
# epsilon = 0.05, 91.1
# epsilon = 0.01, 299

class SAGAN():
    def __init__(self, privacy = False):
      self.img_rows = 52
      self.img_cols = 3
      self.channels = 1
      self.img_shape = (self.img_rows, self.img_cols)
      self.latent_dim = 3

      optimizer = keras.optimizers.Adam()

      self.discriminator = self.build_discriminator()

      # privacy is implemented here.
      if privacy == True:
        print("using differential privacy")
        # Build and compile the discriminator
        self.discriminator.compile(optimizer=DPKerasAdamOptimizer(
          l2_norm_clip=l2_norm_clip,
          noise_multiplier=noise_multiplier,
          num_microbatches=num_microbatches),
          loss= tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.losses.Reduction.NONE), metrics=['accuracy'])

      # Build the generator
      self.generator = self.build_generator()
      self.generator.summary()

      # The generator takes noise as input and generates imgs
      z = Input(shape=(self.latent_dim,))
      img = self.generator(z)

      # For the combined model we will only train the generator
      self.discriminator.trainable = False

      # The discriminator takes generated images as input and determines validity
      valid = self.discriminator(img)

      # The combined model  (stacked generator and discriminator)
      # Trains the generator to fool the discriminator
      self.combined = Model(z, valid)
      self.combined.compile(loss='binary_crossentropy', optimizer=optimizer) # Hinge or binary_cross_entropy


    def build_generator(self):
      noise = Input(shape=(self.latent_dim,))
      y = Dense(self.img_rows*self.img_cols, input_dim=self.latent_dim)(noise)
      #y = LeakyReLU()(y)
      y = Reshape((self.img_rows,self.img_cols,self.channels))(y)
      y = ConvSN2D(4, kernel_size= 2, strides=1, padding="same")(y)
      #y = BatchNormalization()(y)
      #y = LeakyReLU()(y)
      y = SelfAttention2D(4)(y)
      img = Conv2D(1, kernel_size = 2, padding="same", activation="tanh")(y)
      return Model(noise, img)

    def build_discriminator(self):

        model = Sequential()
        model.add(Flatten(input_shape = self.img_shape))
        model.add(Dense(4))
        #model.add(BatchNormalization())
        model.add(Dense(1, activation='sigmoid'))

        img = Input(shape=self.img_shape)
        validity = model(img)
        model.summary()

        return Model(img, validity)

    def train(self, iterations, batch_size, sample_interval, early_stopping, early_stopping_value, generator_losses = [], discriminator_acc = [], correlations = [], accuracy = [], MAPD_collect = [],MSE_collect = [], MAE_collect = []):
      # Adversarial ground truths
      valid = np.ones((batch_size, 1))
      fake = np.zeros((batch_size, 1))
      corr = 0
      MAPD = 0
      MSE = 0
      MAE = 0

      for epoch in range(iterations):

            # ---------------------
            #  Train Discriminator
            # ---------------------

            # Select a random batch of images
            idx = np.random.randint(0, data.shape[0], batch_size)
            imgs = data[idx]

            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))

            # Generate a batch of new images
            gen_imgs = self.generator.predict(noise, verbose = False)
            gen_imgs = gen_imgs.reshape(batch_size, self.img_rows, self.img_cols)

            # Train the discriminator
            d_loss_real = self.discriminator.train_on_batch(imgs, valid)
            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)
            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

            # ---------------------
            #  Train Generator
            # ---------------------
            # Train the generator (to have the discriminator label samples as valid)

            noise = np.random.normal(0, 1,  (batch_size, self.latent_dim))
            g_loss = self.combined.train_on_batch(noise, valid)
            generator_losses = np.append(generator_losses, g_loss)

            if epoch % sample_interval == 0:
              # Plot the progress and save model
              print ("%d [D loss: %f, acc.: %.2f%%] [G loss: %f, corr: %f, MAPD: %f, MSE: %f, MAE: %f]" % (epoch, d_loss[0], 100*d_loss[1], g_loss, corr, MAPD, MSE, MAE))

              # Gets correlation, MSE, MAPD, MAE, and others.
              sample_size = len(data)
              noise = np.random.normal(0, 1,  (sample_size, self.latent_dim))
              gen_imgs1 = self.generator.predict(noise, verbose = False)
              gen_imgs1 = np.array(gen_imgs1).reshape(sample_size*52,3)
              gen_imgs1 = scaler0.inverse_transform(gen_imgs1)

              print(pd.DataFrame(gen_imgs1).describe().loc[['min','mean', 'max', 'std']])
              gen = np.array(gen_imgs1).reshape(sample_size,52,3)
              plt.imshow(tf.reduce_mean(gen[:,:,:], axis = 0))
              plt.show()

              # model
              GAN_fit = LinearRegression().fit(gen_imgs1[:,1:3], gen_imgs1[:,0])
              MAPD = np.mean(abs((real_fit.coef_-GAN_fit.coef_)/real_fit.coef_))*100
              MSE = np.mean((real_fit.coef_-GAN_fit.coef_)**2)
              MAE = np.mean(abs(real_fit.coef_-GAN_fit.coef_))

              corr_artificial = pd.DataFrame(gen_imgs1)
              corr_artificial = corr_artificial.corr()
              corr_artificial = np.array(corr_artificial)
              corr_artificial = np.array(corr_artificial).reshape(len(corr_artificial)*len(corr_artificial))
              corr = pearsonr(corr_artificial,corr_data)[0]

      self.generator.save("prescriptions_einf.h5")


if __name__ == '__main__':
  random.seed(1)
  np.random.seed(1)
  tf.random.set_seed(1)
  iterations = 1000
  N = len(data)
  batch_size = 100
  epochs = iterations/(N/batch_size)
  print(epochs)
  sagan = SAGAN(privacy = True)
  sagan.train(iterations=(iterations), batch_size=batch_size, sample_interval=100, early_stopping = False, early_stopping_value = 50) # 28000/(336/48) = 4000 epochs

random.seed(1)
np.random.seed(1)
tf.random.set_seed(1)

generator = keras.models.load_model('prescriptions_einf.h5', custom_objects={"SelfAttention2D": SelfAttention2D, "ConvSN2D": ConvSN2D})
generated_data = []
sample_size = len(data)
noise = np.random.normal(0, 1, (sample_size, 3))
gen_imgs1 = generator.predict(noise, verbose = False)

gen_imgs1 = np.array(gen_imgs1).reshape(sample_size*52,3)
gen_imgs1 = scaler0.inverse_transform(gen_imgs1)
print(pd.DataFrame(gen_imgs1).describe().loc[['min','mean', 'max', 'std']])
gen = np.array(gen_imgs1).reshape(sample_size,52,3)
plt.imshow(tf.reduce_mean(gen[:,:,:], axis = 0))
plt.show()

np.savetxt("prescriptions_einf.csv", gen_imgs1, delimiter=",")

# model
GAN_fit = LinearRegression().fit(gen_imgs1[:,1:3], gen_imgs1[:,0])
MAPD = np.mean(abs((real_fit.coef_-GAN_fit.coef_)/real_fit.coef_))*100
MSE = np.mean((real_fit.coef_-GAN_fit.coef_)**2)
MAE = np.mean(abs(real_fit.coef_-GAN_fit.coef_))

corr_artificial = pd.DataFrame(gen_imgs1)
corr_artificial = corr_artificial.corr()
corr_artificial = np.array(corr_artificial)
corr_artificial = np.array(corr_artificial).reshape(len(corr_artificial)*len(corr_artificial))

corr = pearsonr(corr_artificial,corr_data)[0]

print(corr)
print(MAPD)
print(MSE)
print(MAE)

"""# medium sample size"""

data = pd.read_csv('prescriptions_medium.csv', sep = ',', na_values=['(NA)']).fillna(0)
data = data.iloc[:,[2,3,5]]
data.describe()
print(pd.DataFrame(data).describe().loc[['min','mean', 'max', 'std']])

# obtain correlations
corr_data = pd.DataFrame(data).corr()
corr_data = np.array(corr_data)
corr_data = np.array(corr_data).reshape(len(corr_data)*len(corr_data))

real_fit = LinearRegression(fit_intercept = True).fit(data.iloc[:,1:4], data.iloc[:,0])
print(real_fit.intercept_)
print("coefs")
print(real_fit.coef_)

from sklearn.preprocessing import MinMaxScaler
scaler0 = MinMaxScaler(feature_range= (-1, 1))
scaler0 = scaler0.fit(data)
data = scaler0.transform(data)
data = np.array(data).reshape(703,52,3)

gen_imgs1 = np.array(data).reshape(703*52,3)
#gen_imgs1 = pd.DataFrame(gen_imgs1).transpose()
gen_imgs1 = scaler0.inverse_transform(gen_imgs1)

gen = np.array(gen_imgs1).reshape(703,52,3)
plt.imshow(tf.reduce_mean(gen[:,:,:], axis = 0))
print(pd.DataFrame(tf.reduce_mean(gen[:,:,:], axis = 0)).describe())

gen_imgs1 = np.array(gen_imgs1)

# model
GAN_fit = LinearRegression().fit(gen_imgs1[:,1:3], gen_imgs1[:,0])
MAPD = np.mean(abs((real_fit.coef_-GAN_fit.coef_)/real_fit.coef_))*100
MSE = np.mean((real_fit.coef_-GAN_fit.coef_)**2)
MAE = np.mean(abs(real_fit.coef_-GAN_fit.coef_))
print("MAPD")
print(MAPD)

corr_artificial = pd.DataFrame(gen_imgs1)
corr_artificial = corr_artificial.corr()
corr_artificial = np.array(corr_artificial)
corr_artificial = np.array(corr_artificial).reshape(len(corr_artificial)*len(corr_artificial))

corr = pearsonr(corr_artificial,corr_data)[0]
print("correlation")
print(corr)

class SAGAN():
    def __init__(self, privacy = False):
      self.img_rows = 52
      self.img_cols = 3
      self.channels = 1
      self.img_shape = (self.img_rows, self.img_cols)
      self.latent_dim = 3

      optimizer = keras.optimizers.Adam()

      if privacy == True:
        # Build and compile the discriminator
        self.discriminator.compile(optimizer=DPKerasAdamOptimizer(
          l2_norm_clip=l2_norm_clip,
          noise_multiplier=noise_multiplier,
          num_microbatches=num_microbatches),
          loss= tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.losses.Reduction.NONE), metrics=['accuracy'])


      self.discriminator = self.build_discriminator()
      self.discriminator.compile(loss='binary_crossentropy', # hinge or binary_crossentropy
                                 optimizer=optimizer,
                                 metrics=['accuracy'])

      # Build the generator
      self.generator = self.build_generator()
      self.generator.summary()

      # The generator takes noise as input and generates imgs
      z = Input(shape=(self.latent_dim,))
      img = self.generator(z)

      # For the combined model we will only train the generator
      self.discriminator.trainable = False

      # The discriminator takes generated images as input and determines validity
      valid = self.discriminator(img)

      # The combined model  (stacked generator and discriminator)
      # Trains the generator to fool the discriminator
      self.combined = Model(z, valid)
      self.combined.compile(loss='binary_crossentropy', optimizer=optimizer) # Hinge or binary_cross_entropy


    def build_generator(self):
      noise = Input(shape=(self.latent_dim,))
      y = Dense(self.img_rows*self.img_cols, input_dim=self.latent_dim)(noise)
      #y = LeakyReLU()(y)
      y = Reshape((self.img_rows,self.img_cols,self.channels))(y)
      y = ConvSN2D(4, kernel_size= 2, strides=1, padding="same")(y)
      #y = BatchNormalization()(y)
      #y = LeakyReLU()(y)
      y = SelfAttention2D(4)(y)
      img = Conv2D(1, kernel_size = 2, padding="same", activation="tanh")(y)
      return Model(noise, img)

    def build_discriminator(self):

        model = Sequential()
        model.add(Flatten(input_shape = self.img_shape))
        model.add(Dense(4))
        #model.add(BatchNormalization())
        model.add(Dense(1, activation='sigmoid'))

        img = Input(shape=self.img_shape)
        validity = model(img)
        model.summary()

        return Model(img, validity)

    def train(self, iterations, batch_size, sample_interval, early_stopping, early_stopping_value, generator_losses = [], discriminator_acc = [], correlations = [], accuracy = [], MAPD_collect = [],MSE_collect = [], MAE_collect = []):
      # Adversarial ground truths
      valid = np.ones((batch_size, 1))
      fake = np.zeros((batch_size, 1))
      corr = 0
      MAPD = 0
      MSE = 0
      MAE = 0
      #fake += 0.05 * np.random.random(fake.shape)
      #valid += 0.05 * np.random.random(valid.shape)

      for epoch in range(iterations):

            # ---------------------
            #  Train Discriminator
            # ---------------------

            # Select a random batch of images
            idx = np.random.randint(0, data.shape[0], batch_size)
            imgs = data[idx]

            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))

            # Generate a batch of new images
            gen_imgs = self.generator.predict(noise, verbose = False)
            gen_imgs = gen_imgs.reshape(batch_size, self.img_rows, self.img_cols)

            # Train the discriminator
            d_loss_real = self.discriminator.train_on_batch(imgs, valid)
            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)
            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

            # ---------------------
            #  Train Generator
            # ---------------------
            # Train the generator (to have the discriminator label samples as valid)

            noise = np.random.normal(0, 1,  (batch_size, self.latent_dim))
            g_loss = self.combined.train_on_batch(noise, valid)
            generator_losses = np.append(generator_losses, g_loss)

            if epoch % sample_interval == 0:
              # Plot the progress and save model
              print ("%d [D loss: %f, acc.: %.2f%%] [G loss: %f, corr: %f, MAPD: %f, MSE: %f, MAE: %f]" % (epoch, d_loss[0], 100*d_loss[1], g_loss, corr, MAPD, MSE, MAE))

              # Gets correlation, MSE, MAPD, MAE, and others.
              sample_size = len(data)
              noise = np.random.normal(0, 1,  (sample_size, self.latent_dim))
              gen_imgs1 = self.generator.predict(noise, verbose = False)
              gen_imgs1 = np.array(gen_imgs1).reshape(sample_size*52,3)
              gen_imgs1 = scaler0.inverse_transform(gen_imgs1)

              print(pd.DataFrame(gen_imgs1).describe().loc[['min','mean', 'max', 'std']])
              gen = np.array(gen_imgs1).reshape(sample_size,52,3)
              plt.imshow(tf.reduce_mean(gen[:,:,:], axis = 0))
              plt.show()

              # model
              GAN_fit = LinearRegression().fit(gen_imgs1[:,1:3], gen_imgs1[:,0])
              MAPD = np.mean(abs((real_fit.coef_-GAN_fit.coef_)/real_fit.coef_))*100
              MSE = np.mean((real_fit.coef_-GAN_fit.coef_)**2)
              MAE = np.mean(abs(real_fit.coef_-GAN_fit.coef_))

              corr_artificial = pd.DataFrame(gen_imgs1)
              corr_artificial = corr_artificial.corr()
              corr_artificial = np.array(corr_artificial)
              corr_artificial = np.array(corr_artificial).reshape(len(corr_artificial)*len(corr_artificial))
              corr = pearsonr(corr_artificial,corr_data)[0]

              # collect
              correlations = np.append(correlations,corr)
              MAPD_collect = np.append(MAPD_collect, MAPD)
              MSE_collect = np.append(MSE_collect, MSE)
              MAE_collect = np.append(MAE_collect, MAE)
              pd.DataFrame(correlations).to_csv("correlations.csv", index = False)
              pd.DataFrame(MAPD_collect).to_csv("MAPD_collect.csv", index = False)
              pd.DataFrame(MSE_collect).to_csv("MSE_collect.csv", index = False)
              pd.DataFrame(MAE_collect).to_csv("MAE_collect.csv", index = False)
      self.generator.save("prescriptions_without_privacy_medium.h5")


if __name__ == '__main__':
  random.seed(1)
  np.random.seed(1)
  tf.random.set_seed(1)
  iterations = 1000
  N = len(data)
  batch_size = 100
  epochs = iterations/(N/batch_size)
  print(epochs)
  sagan = SAGAN(privacy = False)
  sagan.train(iterations=(iterations), batch_size=batch_size, sample_interval=100, early_stopping = False, early_stopping_value = 50) # 28000/(336/48) = 4000 epochs

random.seed(1)
np.random.seed(1)
tf.random.set_seed(1)

generator = keras.models.load_model('prescriptions_without_privacy_medium.h5', custom_objects={"SelfAttention2D": SelfAttention2D, "ConvSN2D": ConvSN2D})
generated_data = []
sample_size = len(data)
noise = np.random.normal(0, 1, (sample_size, 3))
gen_imgs1 = generator.predict(noise, verbose = False)

gen_imgs1 = np.array(gen_imgs1).reshape(sample_size*52,3)
gen_imgs1 = scaler0.inverse_transform(gen_imgs1)
print(pd.DataFrame(gen_imgs1).describe().loc[['min','mean', 'max', 'std']])
gen = np.array(gen_imgs1).reshape(sample_size,52,3)
plt.imshow(tf.reduce_mean(gen[:,:,:], axis = 0))
plt.show()

np.savetxt("prescriptions_without_privacy_medium.csv", gen_imgs1, delimiter=",")

# model
GAN_fit = LinearRegression().fit(gen_imgs1[:,1:3], gen_imgs1[:,0])
MAPD = np.mean(abs((real_fit.coef_-GAN_fit.coef_)/real_fit.coef_))*100
MSE = np.mean((real_fit.coef_-GAN_fit.coef_)**2)
MAE = np.mean(abs(real_fit.coef_-GAN_fit.coef_))

corr_artificial = pd.DataFrame(gen_imgs1)
corr_artificial = corr_artificial.corr()
corr_artificial = np.array(corr_artificial)
corr_artificial = np.array(corr_artificial).reshape(len(corr_artificial)*len(corr_artificial))

corr = pearsonr(corr_artificial,corr_data)[0]

print(corr)
print(MAPD)
print(MSE)
print(MAE)

"""# medium differential privacy"""

from absl import app
from absl import flags
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy
from tensorflow_privacy.privacy.optimizers.dp_optimizer_keras import DPKerasSGDOptimizer, DPKerasAdamOptimizer
from tensorflow_privacy.privacy.analysis.compute_dp_sgd_privacy_lib import compute_dp_sgd_privacy

# hyperparams
N = len(data)
print(N)
# epoch is the number of iterations it takes to completely cover a data set.
# how many iterations would it take to cover a complete data set: dataset/batch_size = (3333/33) = 101
# one epoch is the number of iterations it takes to cover a data set. one epoch = 101 iterations, thus epochs = iterations/101
batch_size = 100
iterations = 1000
num_microbatches = 100

epochs = iterations/(N/batch_size)
print("the number of epochs is " + str(epochs))

lr = 0.001
## noise_multiplier has to be at least .3 to obtain some privacy guarantees.
## the higher the noise_multiplier, the better the privacy, but lower accuracy.
noise_multiplier = 0

## if l2_norm_clip < ||gradient||2, gradient is preserved. if l2_norm_clip > ||gradient||2, then gradient is divided by l2_norm_clip
l2_norm_clip = 2 # see abadi et al 2016

delta= 1/N

compute_dp_sgd_privacy(N, batch_size, noise_multiplier,
                         epochs, delta)

# noise multiplier and corresponding noise multiplier
# 1.74 = 13, 5.09 = 3, 12.64 = 1, 22.7 = 0.5, 153 = 0.05, 510 = 0.01

class SAGAN():
    def __init__(self, privacy = False):
      self.img_rows = 52
      self.img_cols = 3
      self.channels = 1
      self.img_shape = (self.img_rows, self.img_cols)
      self.latent_dim = 3

      optimizer = keras.optimizers.Adam()

      self.discriminator = self.build_discriminator()

      if privacy == True:
        print("using differential privacy")
        # Build and compile the discriminator
        self.discriminator.compile(optimizer=DPKerasAdamOptimizer(
          l2_norm_clip=l2_norm_clip,
          noise_multiplier=noise_multiplier,
          num_microbatches=num_microbatches),
          loss= tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.losses.Reduction.NONE), metrics=['accuracy'])

      # Build the generator
      self.generator = self.build_generator()
      self.generator.summary()

      # The generator takes noise as input and generates imgs
      z = Input(shape=(self.latent_dim,))
      img = self.generator(z)

      # For the combined model we will only train the generator
      self.discriminator.trainable = False

      # The discriminator takes generated images as input and determines validity
      valid = self.discriminator(img)

      # The combined model  (stacked generator and discriminator)
      # Trains the generator to fool the discriminator
      self.combined = Model(z, valid)
      self.combined.compile(loss='binary_crossentropy', optimizer=optimizer) # Hinge or binary_cross_entropy


    def build_generator(self):
      noise = Input(shape=(self.latent_dim,))
      y = Dense(self.img_rows*self.img_cols, input_dim=self.latent_dim)(noise)
      #y = LeakyReLU()(y)
      y = Reshape((self.img_rows,self.img_cols,self.channels))(y)
      y = ConvSN2D(4, kernel_size= 2, strides=1, padding="same")(y)
      #y = BatchNormalization()(y)
      #y = LeakyReLU()(y)
      y = SelfAttention2D(4)(y)
      img = Conv2D(1, kernel_size = 2, padding="same", activation="tanh")(y)
      return Model(noise, img)

    def build_discriminator(self):

        model = Sequential()
        model.add(Flatten(input_shape = self.img_shape))
        model.add(Dense(4))
        #model.add(BatchNormalization())
        model.add(Dense(1, activation='sigmoid'))

        img = Input(shape=self.img_shape)
        validity = model(img)
        model.summary()

        return Model(img, validity)

    def train(self, iterations, batch_size, sample_interval, early_stopping, early_stopping_value, generator_losses = [], discriminator_acc = [], correlations = [], accuracy = [], MAPD_collect = [],MSE_collect = [], MAE_collect = []):
      # Adversarial ground truths
      valid = np.ones((batch_size, 1))
      fake = np.zeros((batch_size, 1))
      corr = 0
      MAPD = 0
      MSE = 0
      MAE = 0
      #fake += 0.05 * np.random.random(fake.shape)
      #valid += 0.05 * np.random.random(valid.shape)

      for epoch in range(iterations):

            # ---------------------
            #  Train Discriminator
            # ---------------------

            # Select a random batch of images
            idx = np.random.randint(0, data.shape[0], batch_size)
            imgs = data[idx]

            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))

            # Generate a batch of new images
            gen_imgs = self.generator.predict(noise, verbose = False)
            gen_imgs = gen_imgs.reshape(batch_size, self.img_rows, self.img_cols)

            # Train the discriminator
            d_loss_real = self.discriminator.train_on_batch(imgs, valid)
            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)
            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

            # ---------------------
            #  Train Generator
            # ---------------------
            # Train the generator (to have the discriminator label samples as valid)

            noise = np.random.normal(0, 1,  (batch_size, self.latent_dim))
            g_loss = self.combined.train_on_batch(noise, valid)
            generator_losses = np.append(generator_losses, g_loss)

            if epoch % sample_interval == 0:
              # Plot the progress and save model
              print ("%d [D loss: %f, acc.: %.2f%%] [G loss: %f, corr: %f, MAPD: %f, MSE: %f, MAE: %f]" % (epoch, d_loss[0], 100*d_loss[1], g_loss, corr, MAPD, MSE, MAE))

              # Gets correlation, MSE, MAPD, MAE, and others.
              sample_size = len(data)
              noise = np.random.normal(0, 1,  (sample_size, self.latent_dim))
              gen_imgs1 = self.generator.predict(noise, verbose = False)
              gen_imgs1 = np.array(gen_imgs1).reshape(sample_size*52,3)
              gen_imgs1 = scaler0.inverse_transform(gen_imgs1)

              print(pd.DataFrame(gen_imgs1).describe().loc[['min','mean', 'max', 'std']])
              gen = np.array(gen_imgs1).reshape(sample_size,52,3)
              plt.imshow(tf.reduce_mean(gen[:,:,:], axis = 0))
              plt.show()

              # model
              GAN_fit = LinearRegression().fit(gen_imgs1[:,1:3], gen_imgs1[:,0])
              MAPD = np.mean(abs((real_fit.coef_-GAN_fit.coef_)/real_fit.coef_))*100
              MSE = np.mean((real_fit.coef_-GAN_fit.coef_)**2)
              MAE = np.mean(abs(real_fit.coef_-GAN_fit.coef_))

              corr_artificial = pd.DataFrame(gen_imgs1)
              corr_artificial = corr_artificial.corr()
              corr_artificial = np.array(corr_artificial)
              corr_artificial = np.array(corr_artificial).reshape(len(corr_artificial)*len(corr_artificial))
              corr = pearsonr(corr_artificial,corr_data)[0]

              # collect
              #correlations = np.append(correlations,corr)
              #MAPD_collect = np.append(MAPD_collect, MAPD)
              #MSE_collect = np.append(MSE_collect, MSE)
              #MAE_collect = np.append(MAE_collect, MAE)
              #pd.DataFrame(correlations).to_csv("correlations.csv", index = False)
              #pd.DataFrame(MAPD_collect).to_csv("MAPD_collect.csv", index = False)
              #pd.DataFrame(MSE_collect).to_csv("MSE_collect.csv", index = False)
              #pd.DataFrame(MAE_collect).to_csv("MAE_collect.csv", index = False)
      self.generator.save("prescriptions_medium_einf.h5")


if __name__ == '__main__':
  random.seed(1)
  np.random.seed(1)
  tf.random.set_seed(1)
  sagan = SAGAN(privacy = True)
  sagan.train(iterations=(iterations), batch_size=batch_size, sample_interval=100, early_stopping = False, early_stopping_value = 50) # 28000/(336/48) = 4000 epochs

random.seed(1)
np.random.seed(1)
tf.random.set_seed(1)

generator = keras.models.load_model('prescriptions_medium_einf.h5', custom_objects={"SelfAttention2D": SelfAttention2D, "ConvSN2D": ConvSN2D})
generated_data = []
sample_size = len(data)
noise = np.random.normal(0, 1, (sample_size, 3))
gen_imgs1 = generator.predict(noise, verbose = False)

gen_imgs1 = np.array(gen_imgs1).reshape(sample_size*52,3)
gen_imgs1 = scaler0.inverse_transform(gen_imgs1)
print(pd.DataFrame(gen_imgs1).describe().loc[['min','mean', 'max', 'std']])
gen = np.array(gen_imgs1).reshape(sample_size,52,3)
plt.imshow(tf.reduce_mean(gen[:,:,:], axis = 0))
plt.show()

np.savetxt("prescriptions_medium_einf.csv", gen_imgs1, delimiter=",")

# model
GAN_fit = LinearRegression().fit(gen_imgs1[:,1:3], gen_imgs1[:,0])
MAPD = np.mean(abs((real_fit.coef_-GAN_fit.coef_)/real_fit.coef_))*100
MSE = np.mean((real_fit.coef_-GAN_fit.coef_)**2)
MAE = np.mean(abs(real_fit.coef_-GAN_fit.coef_))

corr_artificial = pd.DataFrame(gen_imgs1)
corr_artificial = corr_artificial.corr()
corr_artificial = np.array(corr_artificial)
corr_artificial = np.array(corr_artificial).reshape(len(corr_artificial)*len(corr_artificial))

corr = pearsonr(corr_artificial,corr_data)[0]

print(corr)
print(MAPD)
print(MSE)
print(MAE)

"""# smallest sample size"""

data = pd.read_csv('prescriptions_small.csv', sep = ',', na_values=['(NA)']).fillna(0)
data = data.iloc[:,[2,3,5]]
data.describe()
print(pd.DataFrame(data).describe().loc[['min','mean', 'max', 'std']])

# obtain correlations
corr_data = pd.DataFrame(data).corr()
corr_data = np.array(corr_data)
corr_data = np.array(corr_data).reshape(len(corr_data)*len(corr_data))

real_fit = LinearRegression(fit_intercept = True).fit(data.iloc[:,1:4], data.iloc[:,0])
print(real_fit.intercept_)
print("coefs")
print(real_fit.coef_)

from sklearn.preprocessing import MinMaxScaler
scaler0 = MinMaxScaler(feature_range= (-1, 1))
scaler0 = scaler0.fit(data)
data = scaler0.transform(data)
data = np.array(data).reshape(140,52,3)

gen_imgs1 = np.array(data).reshape(140*52,3)
#gen_imgs1 = pd.DataFrame(gen_imgs1).transpose()
gen_imgs1 = scaler0.inverse_transform(gen_imgs1)

gen = np.array(gen_imgs1).reshape(140,52,3)
plt.imshow(tf.reduce_mean(gen[:,:,:], axis = 0))
print(pd.DataFrame(tf.reduce_mean(gen[:,:,:], axis = 0)).describe())

gen_imgs1 = np.array(gen_imgs1)

# model
GAN_fit = LinearRegression().fit(gen_imgs1[:,1:3], gen_imgs1[:,0])
MAPD = np.mean(abs((real_fit.coef_-GAN_fit.coef_)/real_fit.coef_))*100
MSE = np.mean((real_fit.coef_-GAN_fit.coef_)**2)
MAE = np.mean(abs(real_fit.coef_-GAN_fit.coef_))
print("MAPD")
print(MAPD)

corr_artificial = pd.DataFrame(gen_imgs1)
corr_artificial = corr_artificial.corr()
corr_artificial = np.array(corr_artificial)
corr_artificial = np.array(corr_artificial).reshape(len(corr_artificial)*len(corr_artificial))

corr = pearsonr(corr_artificial,corr_data)[0]
print("correlation")
print(corr)

class SAGAN():
    def __init__(self, privacy = False):
      self.img_rows = 52
      self.img_cols = 3
      self.channels = 1
      self.img_shape = (self.img_rows, self.img_cols)
      self.latent_dim = 3

      optimizer = keras.optimizers.Adam()

      if privacy == True:
        # Build and compile the discriminator
        self.discriminator.compile(optimizer=DPKerasAdamOptimizer(
          l2_norm_clip=l2_norm_clip,
          noise_multiplier=noise_multiplier,
          num_microbatches=num_microbatches),
          loss= tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.losses.Reduction.NONE), metrics=['accuracy'])


      self.discriminator = self.build_discriminator()
      self.discriminator.compile(loss='binary_crossentropy', # hinge or binary_crossentropy
                                 optimizer=optimizer,
                                 metrics=['accuracy'])

      # Build the generator
      self.generator = self.build_generator()
      self.generator.summary()

      # The generator takes noise as input and generates imgs
      z = Input(shape=(self.latent_dim,))
      img = self.generator(z)

      # For the combined model we will only train the generator
      self.discriminator.trainable = False

      # The discriminator takes generated images as input and determines validity
      valid = self.discriminator(img)

      # The combined model  (stacked generator and discriminator)
      # Trains the generator to fool the discriminator
      self.combined = Model(z, valid)
      self.combined.compile(loss='binary_crossentropy', optimizer=optimizer) # Hinge or binary_cross_entropy


    def build_generator(self):
      noise = Input(shape=(self.latent_dim,))
      y = Dense(self.img_rows*self.img_cols, input_dim=self.latent_dim)(noise)
      #y = LeakyReLU()(y)
      y = Reshape((self.img_rows,self.img_cols,self.channels))(y)
      y = ConvSN2D(4, kernel_size= 2, strides=1, padding="same")(y)
      #y = BatchNormalization()(y)
      #y = LeakyReLU()(y)
      y = SelfAttention2D(4)(y)
      img = Conv2D(1, kernel_size = 2, padding="same", activation="tanh")(y)
      return Model(noise, img)

    def build_discriminator(self):

        model = Sequential()
        model.add(Flatten(input_shape = self.img_shape))
        model.add(Dense(4))
        #model.add(BatchNormalization())
        model.add(Dense(1, activation='sigmoid'))

        img = Input(shape=self.img_shape)
        validity = model(img)
        model.summary()

        return Model(img, validity)

    def train(self, iterations, batch_size, sample_interval, early_stopping, early_stopping_value, generator_losses = [], discriminator_acc = [], correlations = [], accuracy = [], MAPD_collect = [],MSE_collect = [], MAE_collect = []):
      # Adversarial ground truths
      valid = np.ones((batch_size, 1))
      fake = np.zeros((batch_size, 1))
      corr = 0
      MAPD = 0
      MSE = 0
      MAE = 0
      #fake += 0.05 * np.random.random(fake.shape)
      #valid += 0.05 * np.random.random(valid.shape)

      for epoch in range(iterations):

            # ---------------------
            #  Train Discriminator
            # ---------------------

            # Select a random batch of images
            idx = np.random.randint(0, data.shape[0], batch_size)
            imgs = data[idx]

            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))

            # Generate a batch of new images
            gen_imgs = self.generator.predict(noise, verbose = False)
            gen_imgs = gen_imgs.reshape(batch_size, self.img_rows, self.img_cols)

            # Train the discriminator
            d_loss_real = self.discriminator.train_on_batch(imgs, valid)
            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)
            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

            # ---------------------
            #  Train Generator
            # ---------------------
            # Train the generator (to have the discriminator label samples as valid)

            noise = np.random.normal(0, 1,  (batch_size, self.latent_dim))
            g_loss = self.combined.train_on_batch(noise, valid)
            generator_losses = np.append(generator_losses, g_loss)

            if epoch % sample_interval == 0:
              # Plot the progress and save model
              print ("%d [D loss: %f, acc.: %.2f%%] [G loss: %f, corr: %f, MAPD: %f, MSE: %f, MAE: %f]" % (epoch, d_loss[0], 100*d_loss[1], g_loss, corr, MAPD, MSE, MAE))

              # Gets correlation, MSE, MAPD, MAE, and others.
              sample_size = len(data)
              noise = np.random.normal(0, 1,  (sample_size, self.latent_dim))
              gen_imgs1 = self.generator.predict(noise, verbose = False)
              gen_imgs1 = np.array(gen_imgs1).reshape(sample_size*52,3)
              gen_imgs1 = scaler0.inverse_transform(gen_imgs1)

              print(pd.DataFrame(gen_imgs1).describe().loc[['min','mean', 'max', 'std']])
              gen = np.array(gen_imgs1).reshape(sample_size,52,3)
              plt.imshow(tf.reduce_mean(gen[:,:,:], axis = 0))
              plt.show()

              # model
              GAN_fit = LinearRegression().fit(gen_imgs1[:,1:3], gen_imgs1[:,0])
              MAPD = np.mean(abs((real_fit.coef_-GAN_fit.coef_)/real_fit.coef_))*100
              MSE = np.mean((real_fit.coef_-GAN_fit.coef_)**2)
              MAE = np.mean(abs(real_fit.coef_-GAN_fit.coef_))

              corr_artificial = pd.DataFrame(gen_imgs1)
              corr_artificial = corr_artificial.corr()
              corr_artificial = np.array(corr_artificial)
              corr_artificial = np.array(corr_artificial).reshape(len(corr_artificial)*len(corr_artificial))
              corr = pearsonr(corr_artificial,corr_data)[0]

              # collect
              correlations = np.append(correlations,corr)
              MAPD_collect = np.append(MAPD_collect, MAPD)
              MSE_collect = np.append(MSE_collect, MSE)
              MAE_collect = np.append(MAE_collect, MAE)
              pd.DataFrame(correlations).to_csv("correlations.csv", index = False)
              pd.DataFrame(MAPD_collect).to_csv("MAPD_collect.csv", index = False)
              pd.DataFrame(MSE_collect).to_csv("MSE_collect.csv", index = False)
              pd.DataFrame(MAE_collect).to_csv("MAE_collect.csv", index = False)
      self.generator.save("prescriptions_without_privacy_small.h5")


if __name__ == '__main__':
  random.seed(1)
  np.random.seed(1)
  tf.random.set_seed(1)
  iterations = 1000
  N = len(data)
  batch_size = 100
  epochs = iterations/(N/batch_size)
  print(epochs)
  sagan = SAGAN(privacy = False)
  sagan.train(iterations=(iterations), batch_size=batch_size, sample_interval=100, early_stopping = False, early_stopping_value = 50) # 28000/(336/48) = 4000 epochs

random.seed(1)
np.random.seed(1)
tf.random.set_seed(1)

generator = keras.models.load_model('prescriptions_without_privacy_small.h5', custom_objects={"SelfAttention2D": SelfAttention2D, "ConvSN2D": ConvSN2D})
generated_data = []
sample_size = len(data)
noise = np.random.normal(0, 1, (sample_size, 3))
gen_imgs1 = generator.predict(noise, verbose = False)

gen_imgs1 = np.array(gen_imgs1).reshape(sample_size*52,3)
gen_imgs1 = scaler0.inverse_transform(gen_imgs1)
print(pd.DataFrame(gen_imgs1).describe().loc[['min','mean', 'max', 'std']])
gen = np.array(gen_imgs1).reshape(sample_size,52,3)
plt.imshow(tf.reduce_mean(gen[:,:,:], axis = 0))
plt.show()

np.savetxt("prescriptions_without_privacy_small.csv", gen_imgs1, delimiter=",")

# model
GAN_fit = LinearRegression().fit(gen_imgs1[:,1:3], gen_imgs1[:,0])
MAPD = np.mean(abs((real_fit.coef_-GAN_fit.coef_)/real_fit.coef_))*100
MSE = np.mean((real_fit.coef_-GAN_fit.coef_)**2)
MAE = np.mean(abs(real_fit.coef_-GAN_fit.coef_))

corr_artificial = pd.DataFrame(gen_imgs1)
corr_artificial = corr_artificial.corr()
corr_artificial = np.array(corr_artificial)
corr_artificial = np.array(corr_artificial).reshape(len(corr_artificial)*len(corr_artificial))

corr = pearsonr(corr_artificial,corr_data)[0]

print(corr)
print(MAPD)
print(MSE)
print(MAE)

"""# smallest with differential privacy"""

from absl import app
from absl import flags
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy
from tensorflow_privacy.privacy.optimizers.dp_optimizer_keras import DPKerasSGDOptimizer, DPKerasAdamOptimizer
from tensorflow_privacy.privacy.analysis.compute_dp_sgd_privacy_lib import compute_dp_sgd_privacy

# hyperparams
N = len(data)
print(N)
# epoch is the number of iterations it takes to completely cover a data set.
# how many iterations would it take to cover a complete data set: dataset/batch_size = (3333/33) = 101
# one epoch is the number of iterations it takes to cover a data set. one epoch = 101 iterations, thus epochs = iterations/101
batch_size = 100
iterations = 1000
num_microbatches = 100

epochs = iterations/(N/batch_size)
print("the number of epochs is " + str(epochs))

lr = 0.001
## noise_multiplier has to be at least .3 to obtain some privacy guarantees.
## the higher the noise_multiplier, the better the privacy, but lower accuracy.
noise_multiplier = 0
## if l2_norm_clip < ||gradient||2, gradient is preserved. if l2_norm_clip > ||gradient||2, then gradient is divided by l2_norm_clip
l2_norm_clip = 2 # see abadi et al 2016

delta= 1/N

compute_dp_sgd_privacy(N, batch_size, noise_multiplier,
                         epochs, delta)

# noise multiplier and epsilon
# 1101 = 0.01, 483 = 0.05, 90.4 = 0.5, 52 = 1, 21.9 = 3, 7.37 = 13

class SAGAN():
    def __init__(self, privacy = False):
      self.img_rows = 52
      self.img_cols = 3
      self.channels = 1
      self.img_shape = (self.img_rows, self.img_cols)
      self.latent_dim = 3

      optimizer = keras.optimizers.Adam()

      self.discriminator = self.build_discriminator()

      if privacy == True:
        print("using differential privacy")
        # Build and compile the discriminator
        self.discriminator.compile(optimizer=DPKerasAdamOptimizer(
          l2_norm_clip=l2_norm_clip,
          noise_multiplier=noise_multiplier,
          num_microbatches=num_microbatches),
          loss= tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.losses.Reduction.NONE), metrics=['accuracy'])

      # Build the generator
      self.generator = self.build_generator()
      self.generator.summary()

      # The generator takes noise as input and generates imgs
      z = Input(shape=(self.latent_dim,))
      img = self.generator(z)

      # For the combined model we will only train the generator
      self.discriminator.trainable = False

      # The discriminator takes generated images as input and determines validity
      valid = self.discriminator(img)

      # The combined model  (stacked generator and discriminator)
      # Trains the generator to fool the discriminator
      self.combined = Model(z, valid)
      self.combined.compile(loss='binary_crossentropy', optimizer=optimizer) # Hinge or binary_cross_entropy


    def build_generator(self):
      noise = Input(shape=(self.latent_dim,))
      y = Dense(self.img_rows*self.img_cols, input_dim=self.latent_dim)(noise)
      #y = LeakyReLU()(y)
      y = Reshape((self.img_rows,self.img_cols,self.channels))(y)
      y = ConvSN2D(4, kernel_size= 2, strides=1, padding="same")(y)
      #y = BatchNormalization()(y)
      #y = LeakyReLU()(y)
      y = SelfAttention2D(4)(y)
      img = Conv2D(1, kernel_size = 2, padding="same", activation="tanh")(y)
      return Model(noise, img)

    def build_discriminator(self):

        model = Sequential()
        model.add(Flatten(input_shape = self.img_shape))
        model.add(Dense(4))
        #model.add(BatchNormalization())
        model.add(Dense(1, activation='sigmoid'))

        img = Input(shape=self.img_shape)
        validity = model(img)
        model.summary()

        return Model(img, validity)

    def train(self, iterations, batch_size, sample_interval, early_stopping, early_stopping_value, generator_losses = [], discriminator_acc = [], correlations = [], accuracy = [], MAPD_collect = [],MSE_collect = [], MAE_collect = []):
      # Adversarial ground truths
      valid = np.ones((batch_size, 1))
      fake = np.zeros((batch_size, 1))
      corr = 0
      MAPD = 0
      MSE = 0
      MAE = 0
      #fake += 0.05 * np.random.random(fake.shape)
      #valid += 0.05 * np.random.random(valid.shape)

      for epoch in range(iterations):

            # ---------------------
            #  Train Discriminator
            # ---------------------

            # Select a random batch of images
            idx = np.random.randint(0, data.shape[0], batch_size)
            imgs = data[idx]

            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))

            # Generate a batch of new images
            gen_imgs = self.generator.predict(noise, verbose = False)
            gen_imgs = gen_imgs.reshape(batch_size, self.img_rows, self.img_cols)

            # Train the discriminator
            d_loss_real = self.discriminator.train_on_batch(imgs, valid)
            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)
            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

            # ---------------------
            #  Train Generator
            # ---------------------
            # Train the generator (to have the discriminator label samples as valid)

            noise = np.random.normal(0, 1,  (batch_size, self.latent_dim))
            g_loss = self.combined.train_on_batch(noise, valid)
            generator_losses = np.append(generator_losses, g_loss)

            if epoch % sample_interval == 0:
              # Plot the progress and save model
              print ("%d [D loss: %f, acc.: %.2f%%] [G loss: %f, corr: %f, MAPD: %f, MSE: %f, MAE: %f]" % (epoch, d_loss[0], 100*d_loss[1], g_loss, corr, MAPD, MSE, MAE))

              # Gets correlation, MSE, MAPD, MAE, and others.
              sample_size = len(data)
              noise = np.random.normal(0, 1,  (sample_size, self.latent_dim))
              gen_imgs1 = self.generator.predict(noise, verbose = False)
              gen_imgs1 = np.array(gen_imgs1).reshape(sample_size*52,3)
              gen_imgs1 = scaler0.inverse_transform(gen_imgs1)

              print(pd.DataFrame(gen_imgs1).describe().loc[['min','mean', 'max', 'std']])
              gen = np.array(gen_imgs1).reshape(sample_size,52,3)
              plt.imshow(tf.reduce_mean(gen[:,:,:], axis = 0))
              plt.show()

              # model
              GAN_fit = LinearRegression().fit(gen_imgs1[:,1:3], gen_imgs1[:,0])
              MAPD = np.mean(abs((real_fit.coef_-GAN_fit.coef_)/real_fit.coef_))*100
              MSE = np.mean((real_fit.coef_-GAN_fit.coef_)**2)
              MAE = np.mean(abs(real_fit.coef_-GAN_fit.coef_))

              corr_artificial = pd.DataFrame(gen_imgs1)
              corr_artificial = corr_artificial.corr()
              corr_artificial = np.array(corr_artificial)
              corr_artificial = np.array(corr_artificial).reshape(len(corr_artificial)*len(corr_artificial))
              corr = pearsonr(corr_artificial,corr_data)[0]
      self.generator.save("prescriptions_small_e001.h5")


if __name__ == '__main__':
  random.seed(1)
  np.random.seed(1)
  tf.random.set_seed(1)
  sagan = SAGAN(privacy = True)
  sagan.train(iterations=(iterations), batch_size=batch_size, sample_interval=100, early_stopping = False, early_stopping_value = 50)

random.seed(1)
np.random.seed(1)
tf.random.set_seed(1)

generator = keras.models.load_model('prescriptions_small_e001.h5', custom_objects={"SelfAttention2D": SelfAttention2D, "ConvSN2D": ConvSN2D})
generated_data = []
sample_size = len(data)
noise = np.random.normal(0, 1, (sample_size, 3))
gen_imgs1 = generator.predict(noise, verbose = False)

gen_imgs1 = np.array(gen_imgs1).reshape(sample_size*52,3)
gen_imgs1 = scaler0.inverse_transform(gen_imgs1)
print(pd.DataFrame(gen_imgs1).describe().loc[['min','mean', 'max', 'std']])
gen = np.array(gen_imgs1).reshape(sample_size,52,3)
plt.imshow(tf.reduce_mean(gen[:,:,:], axis = 0))
plt.show()

np.savetxt("prescriptions_small_e001.csv", gen_imgs1, delimiter=",")

# model
GAN_fit = LinearRegression().fit(gen_imgs1[:,1:3], gen_imgs1[:,0])
MAPD = np.mean(abs((real_fit.coef_-GAN_fit.coef_)/real_fit.coef_))*100
MSE = np.mean((real_fit.coef_-GAN_fit.coef_)**2)
MAE = np.mean(abs(real_fit.coef_-GAN_fit.coef_))

corr_artificial = pd.DataFrame(gen_imgs1)
corr_artificial = corr_artificial.corr()
corr_artificial = np.array(corr_artificial)
corr_artificial = np.array(corr_artificial).reshape(len(corr_artificial)*len(corr_artificial))

corr = pearsonr(corr_artificial,corr_data)[0]

print(corr)
print(MAPD)
print(MSE)
print(MAE)